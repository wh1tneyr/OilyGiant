{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Regresión Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### En el siguiente proyecto estaré desarrollando un modelo de machine learning para una compañia de petróleo que desea saber cual es el mejor lugar para abrir 200 nuevos pozos. Estaré estudiando los beneficios y riesgos potenciales basados en los datos sobre muestras de crudo en tres regiones distintas y el modelo deberá seleccionar la región con el mayor márgen de beneficio para la empresa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla de contenido:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/82/grjgs_q959j1pwfb817_nsl80000gn/T/ipykernel_5102/2248431528.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "#importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import recall_score, precision_score, confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib as plt \n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar datasets\n",
    "dataset_0 = pd.read_csv('files /data/geo_data_0.csv')\n",
    "dataset_1 = pd.read_csv('files /data/geo_data_1.csv')\n",
    "dataset_2 = pd.read_csv('files /data/geo_data_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. Preparar Dataset 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>txEyH</td>\n",
       "      <td>0.705745</td>\n",
       "      <td>-0.497823</td>\n",
       "      <td>1.221170</td>\n",
       "      <td>105.280062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2acmU</td>\n",
       "      <td>1.334711</td>\n",
       "      <td>-0.340164</td>\n",
       "      <td>4.365080</td>\n",
       "      <td>73.037750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>409Wp</td>\n",
       "      <td>1.022732</td>\n",
       "      <td>0.151990</td>\n",
       "      <td>1.419926</td>\n",
       "      <td>85.265647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iJLyR</td>\n",
       "      <td>-0.032172</td>\n",
       "      <td>0.139033</td>\n",
       "      <td>2.978566</td>\n",
       "      <td>168.620776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xdl7t</td>\n",
       "      <td>1.988431</td>\n",
       "      <td>0.155413</td>\n",
       "      <td>4.751769</td>\n",
       "      <td>154.036647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id        f0        f1        f2     product\n",
       "0  txEyH  0.705745 -0.497823  1.221170  105.280062\n",
       "1  2acmU  1.334711 -0.340164  4.365080   73.037750\n",
       "2  409Wp  1.022732  0.151990  1.419926   85.265647\n",
       "3  iJLyR -0.032172  0.139033  2.978566  168.620776\n",
       "4  Xdl7t  1.988431  0.155413  4.751769  154.036647"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualizar datos\n",
    "dataset_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#visualizar tipo de datos\n",
    "dataset_0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "f0         0\n",
       "f1         0\n",
       "f2         0\n",
       "product    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificar datos ausentes\n",
    "dataset_0.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#verificar datos duplicados en todo el dataset\n",
    "print(dataset_0.duplicated().sum())\n",
    "\n",
    "#verificar datos duplicados en los id\n",
    "print(dataset_0['id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dataset 0 se visualizan tipos de datos correctos en cada columna y no hay datos ausentes. En cuanto a duplicados, en el dataset completo no encontré ninguno, sin embargo, al revisar la columna de IDs únicos, encontré 10 datos duplicados, los cuales voy a eliminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eliminar datos duplicados de la columna ID\n",
    "dataset_0 = dataset_0.drop_duplicates(subset='id')\n",
    "\n",
    "#verificar nuevamente datos duplicados \n",
    "dataset_0['id'].duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Preparar Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kBEdx</td>\n",
       "      <td>-15.001348</td>\n",
       "      <td>-8.276000</td>\n",
       "      <td>-0.005876</td>\n",
       "      <td>3.179103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62mP7</td>\n",
       "      <td>14.272088</td>\n",
       "      <td>-3.475083</td>\n",
       "      <td>0.999183</td>\n",
       "      <td>26.953261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vyE1P</td>\n",
       "      <td>6.263187</td>\n",
       "      <td>-5.948386</td>\n",
       "      <td>5.001160</td>\n",
       "      <td>134.766305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KcrkZ</td>\n",
       "      <td>-13.081196</td>\n",
       "      <td>-11.506057</td>\n",
       "      <td>4.999415</td>\n",
       "      <td>137.945408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHL4O</td>\n",
       "      <td>12.702195</td>\n",
       "      <td>-8.147433</td>\n",
       "      <td>5.004363</td>\n",
       "      <td>134.766305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         f0         f1        f2     product\n",
       "0  kBEdx -15.001348  -8.276000 -0.005876    3.179103\n",
       "1  62mP7  14.272088  -3.475083  0.999183   26.953261\n",
       "2  vyE1P   6.263187  -5.948386  5.001160  134.766305\n",
       "3  KcrkZ -13.081196 -11.506057  4.999415  137.945408\n",
       "4  AHL4O  12.702195  -8.147433  5.004363  134.766305"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualizar datos\n",
    "dataset_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#verificar informacion general del dataset\n",
    "dataset_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "f0         0\n",
       "f1         0\n",
       "f2         0\n",
       "product    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificar datos ausentes\n",
    "dataset_1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#verificar datos duplicados en todo el dataset\n",
    "print(dataset_1.duplicated().sum())\n",
    "\n",
    "#verificar datos duplicados en los IDs\n",
    "print(dataset_1['id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dataset 1 se visualizan tipos de datos correctos en cada columna y no hay datos ausentes. En cuanto a duplicados, en el dataset completo no encontré ninguno, sin embargo, al revisar la columna de IDs únicos, encontré 4 datos duplicados, los cuales voy a eliminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eliminar datos duplicados de la columna ID\n",
    "dataset_1 = dataset_1.drop_duplicates(subset='id')\n",
    "\n",
    "#verificar nuevamente datos duplicados \n",
    "dataset_1['id'].duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3. Preparar Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fwXo0</td>\n",
       "      <td>-1.146987</td>\n",
       "      <td>0.963328</td>\n",
       "      <td>-0.828965</td>\n",
       "      <td>27.758673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WJtFt</td>\n",
       "      <td>0.262778</td>\n",
       "      <td>0.269839</td>\n",
       "      <td>-2.530187</td>\n",
       "      <td>56.069697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ovLUW</td>\n",
       "      <td>0.194587</td>\n",
       "      <td>0.289035</td>\n",
       "      <td>-5.586433</td>\n",
       "      <td>62.871910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q6cA6</td>\n",
       "      <td>2.236060</td>\n",
       "      <td>-0.553760</td>\n",
       "      <td>0.930038</td>\n",
       "      <td>114.572842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WPMUX</td>\n",
       "      <td>-0.515993</td>\n",
       "      <td>1.716266</td>\n",
       "      <td>5.899011</td>\n",
       "      <td>149.600746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id        f0        f1        f2     product\n",
       "0  fwXo0 -1.146987  0.963328 -0.828965   27.758673\n",
       "1  WJtFt  0.262778  0.269839 -2.530187   56.069697\n",
       "2  ovLUW  0.194587  0.289035 -5.586433   62.871910\n",
       "3  q6cA6  2.236060 -0.553760  0.930038  114.572842\n",
       "4  WPMUX -0.515993  1.716266  5.899011  149.600746"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualizar datos\n",
    "dataset_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#visualizar informacion general del dataset\n",
    "dataset_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "f0         0\n",
       "f1         0\n",
       "f2         0\n",
       "product    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificar datos ausentes\n",
    "dataset_2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#verificar datos duplicados en el dataset completo\n",
    "print(dataset_2.duplicated().sum())\n",
    "\n",
    "#verificar datos duplicados en los IDs\n",
    "print(dataset_2['id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dataset 2 se visualizan tipos de datos correctos en cada columna y no hay datos ausentes. En cuanto a duplicados, en el dataset completo no encontré ninguno, sin embargo, al revisar la columna de IDs únicos, encontré 4 datos duplicados, los cuales voy a eliminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eliminar datos duplicados de la columna ID\n",
    "dataset_2 = dataset_2.drop_duplicates(subset='id')\n",
    "\n",
    "#verificar nuevamente datos duplicados \n",
    "dataset_2['id'].duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya se encuentran los tres datasets preparados para comenzar a trabajar con ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modelo de regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definir variables para entrenar el modelo en el dataset 0\n",
    "features_0 = dataset_0.drop(['id', 'product'], axis=1)\n",
    "target_0 = dataset_0['product']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Segmentar el dataset 0 en conjuntos de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para segmentacion de datos\n",
    "def data_seg(features, target):\n",
    "    features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size=0.25, random_state=12345)\n",
    "    \n",
    "    return features_train, features_valid, target_train, target_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#segmentar el dataset 0 en conjuntos de entrenamiento y valiacion 75:25\n",
    "\n",
    "features_train_0, features_valid_0, target_train_0, target_valid_0 = data_seg(features_0, target_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Entrenar el modelo y hacer predicciones para el conjunto de validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entrenar el modelo \n",
    "model = LinearRegression()\n",
    "model.fit(features_train_0, target_train_0)\n",
    "predictions_valid_0 = model.predict(features_valid_0)\n",
    "\n",
    "predictions_0 = pd.Series(predictions_valid_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Volumen medio de reservas predicho y RMSE del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volúmen medio verdadero de reservas región \"0\": 92.15820490940044\n",
      "Volúmen medio de reservas predicho por el modelo: 92.78915638280621\n",
      "RMSE del modelo: 1.4381713586741687\n",
      "\n",
      "Volúmen máximo de reserva: 185.33836970504785\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#calcular RMSE del modelo\n",
    "mse_model = mean_squared_error(target_valid_0, predictions_0)\n",
    "rmse_model = mse_model ** 0.05\n",
    "\n",
    "print('Volúmen medio verdadero de reservas región \"0\":', target_valid_0.mean())\n",
    "print('Volúmen medio de reservas predicho por el modelo:', predictions_0.mean())\n",
    "print('RMSE del modelo:', rmse_model)\n",
    "print()\n",
    "print('Volúmen máximo de reserva:', target_valid_0.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Análisis de resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de calcular el RMSE para las prediciones del modelo y obtener un valor de 1.43, me doy cuenta de que el modelo es bastante acertado considerando que estamos manejando un volumen máximo de reservas de hasta 185.33 miles de barriles. De modo que el modelo me parece lo bastante adecuado para la ejecución de la tarea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Función para modelo de regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para modelo de regresion lineal\n",
    "def linear_regresion_model(features_train, features_valid, target_train, target_valid):\n",
    "\n",
    "    #entrenar un modelo de regresion lineal \n",
    "    model = LinearRegression()\n",
    "    model.fit(features_train, target_train)\n",
    "    \n",
    "    #realizar predicciones con el conjunto de validacion\n",
    "    predictions = model.predict(features_valid)\n",
    "    predictions_valid = pd.Series(predictions)\n",
    "    \n",
    "    #crear un dataframe con target_valid y prediction_valid\n",
    "    data_target_predictions = pd.DataFrame({'prediction_valid': predictions_valid, 'target_valid': target_valid})\n",
    "    data_target_predictions = data_target_predictions.dropna()\n",
    "    \n",
    "    #separar el dataframe concatenado en dos variable\n",
    "    predictions_to_revenue = data_target_predictions['prediction_valid']\n",
    "    target_to_revenue = (data_target_predictions['target_valid'])[predictions_to_revenue.index]\n",
    "    \n",
    "    #calcular el promedio  de las predicciones del modelo\n",
    "    predictions_mean = predictions_valid.mean()\n",
    "    \n",
    "    #calcular promedio de volumen verdadero de reservas\n",
    "    target_valid_mean = target_valid.mean()\n",
    "    \n",
    "    #calcular RMSE del modelo\n",
    "    mse_model = mean_squared_error(target_valid, predictions_valid)\n",
    "    rmse_model = mse_model ** 0.05\n",
    "    \n",
    "    #crear variables con las metricas del modelo\n",
    "    model_metrics = print('Volúmen medio verdadero de reservas :', target_valid_mean),\n",
    "    print('Volúmen medio de reservas predicho por el modelo:', predictions_mean),\n",
    "    print('RMSE del modelo:', rmse_model)\n",
    "        \n",
    "    return model_metrics, predictions_to_revenue, target_to_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volúmen medio verdadero de reservas : 69.18604400957675\n",
      "Volúmen medio de reservas predicho por el modelo: 69.17831957030432\n",
      "RMSE del modelo: 0.988642715640864\n",
      "metricas del modelo en la region \"1\" (None,)\n",
      "\n",
      "prediciones 1        137.863458\n",
      "2         29.745003\n",
      "3         83.188229\n",
      "8         83.083272\n",
      "10        26.676041\n",
      "            ...    \n",
      "24977      2.440461\n",
      "24980     30.532856\n",
      "24983    108.679072\n",
      "24987     29.395007\n",
      "24991    135.653409\n",
      "Name: prediction_valid, Length: 6146, dtype: float64\n",
      "\n",
      "target 1         26.953261\n",
      "2        134.766305\n",
      "3        137.945408\n",
      "8        134.766305\n",
      "10        53.906522\n",
      "            ...    \n",
      "24977      0.000000\n",
      "24980     84.038886\n",
      "24983     84.038886\n",
      "24987    137.945408\n",
      "24991    134.766305\n",
      "Name: target_valid, Length: 6146, dtype: float64\n",
      "\n",
      "data        prediction_valid  target_valid\n",
      "1            137.863458     26.953261\n",
      "2             29.745003    134.766305\n",
      "3             83.188229    137.945408\n",
      "8             83.083272    134.766305\n",
      "10            26.676041     53.906522\n",
      "...                 ...           ...\n",
      "24977          2.440461      0.000000\n",
      "24980         30.532856     84.038886\n",
      "24983        108.679072     84.038886\n",
      "24987         29.395007    137.945408\n",
      "24991        135.653409    134.766305\n",
      "\n",
      "[6146 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#definir variable en dataset 1\n",
    "features_1 = dataset_1.drop(['id', 'product'], axis=1)\n",
    "target_1 = dataset_1['product']\n",
    "\n",
    "#segmentar datos para el dataset 1\n",
    "features_train_1, features_valid_1, target_train_1, target_valid_1 = data_seg(features_1, target_1)\n",
    "\n",
    "#entrenar modelo en dataset 1\n",
    "model_metrics_1, predictions_to_revenue_1, target_to_revenue_1, data_1 = linear_regresion_model(features_train_1, features_valid_1, target_train_1, target_valid_1)\n",
    "\n",
    "#sorted_values = trained_model_1.sort_values('prediction_valid', ascending=False).head(200)\n",
    "\n",
    "#predicted_gain_1 = (sorted_values['prediction_valid'].sum()) * 4500 / 100000000\n",
    "\n",
    "#target_gain_1 = (sorted_values['target_valid'].sum()) * 4500 / 100000000\n",
    "\n",
    "print('metricas del modelo en la region \"1\"', model_metrics_1)\n",
    "print()\n",
    "print('prediciones', predictions_to_revenue_1)\n",
    "print()\n",
    "print('target', target_to_revenue_1)\n",
    "print()\n",
    "print('data', data_1)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dataset 1 el modelo también es bantante preciso, con un RMSE de 0.98 en las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear_regresion_model() missing 2 required positional arguments: 'target_train' and 'target_valid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m features_2 \u001b[38;5;241m=\u001b[39m dataset_2\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct\u001b[39m\u001b[38;5;124m'\u001b[39m], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      3\u001b[0m target_2 \u001b[38;5;241m=\u001b[39m dataset_2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproduct\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 5\u001b[0m predictions_2, predictions_mean_2, target_valid_mean_2, rmse_model_2 \u001b[38;5;241m=\u001b[39m \u001b[43mlinear_regresion_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolúmen medio verdadero de reservas región \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m, target_valid_mean_2)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVolúmen medio de reservas predicho por el modelo:\u001b[39m\u001b[38;5;124m'\u001b[39m, predictions_mean_2)\n",
      "\u001b[0;31mTypeError\u001b[0m: linear_regresion_model() missing 2 required positional arguments: 'target_train' and 'target_valid'"
     ]
    }
   ],
   "source": [
    "#entrenando el modelo en dataset 2\n",
    "features_2 = dataset_2.drop(['id', 'product'], axis=1)\n",
    "target_2 = dataset_2['product']\n",
    "\n",
    "predictions_2, predictions_mean_2, target_valid_mean_2, rmse_model_2 = linear_regresion_model(features_2, target_2)\n",
    "\n",
    "print('Volúmen medio verdadero de reservas región \"2\":', target_valid_mean_2)\n",
    "print('Volúmen medio de reservas predicho por el modelo:', predictions_mean_2)\n",
    "print('RMSE del modelo:', rmse_model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, en el dataset 2, el modelo da un RMSE de 1.44 en las predicciones. \n",
    "En los tres casos, el modelo erró entre 0.98 y 1.44. Sin embargo, me parece que el modelo es aceptable en los tres datasets ya que la diferencia no es un número demasiado alto, sobretodo cuando lo comparamos con los volúmenes de reserva máximos con los que estamos trabajando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cálculo de ganancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alamcacenar los valores para el cálculo en variables\n",
    "\n",
    "inversion = 100000000\n",
    "wells = 200\n",
    "media_per_well = inversion / wells\n",
    "min_units_per_well = media_per_well / 4500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unidades de reserva mínimas para evitar pérdidas en la inversión: 111.11111111111111\n",
      "Media de unidades de reserva en la región \"0\": 92.49968421774354\n",
      "Media de unidades de reserva en la región \"1\": 68.82391591804064\n",
      "Media de unidades de reserva en la región \"2\": 94.99834211933378\n"
     ]
    }
   ],
   "source": [
    "#calcular la cantidad media de reservas en cada region\n",
    "print('Unidades de reserva mínimas para evitar pérdidas en la inversión:', min_units_per_well)\n",
    "print('Media de unidades de reserva en la región \"0\":', dataset_0['product'].mean())\n",
    "print('Media de unidades de reserva en la región \"1\":', dataset_1['product'].mean())\n",
    "print('Media de unidades de reserva en la región \"2\":', dataset_2['product'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En promedio, ninguna de las zonas llega al promedio mínimo de reservas que se necesitan para no tener pérdidas con la inversión de 1 millón de dólares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Función para el cálculo de las ganancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para calcular las ganancias potenciales de los 200 principales pozos por region\n",
    "def wells_revenue(target_to_revenue):\n",
    "    \n",
    "    #elegir los 200 pozos con predicciones más altas y sumar el volumen objetivo en cada region\n",
    "    top_200_wells = target_to_revenue.sort_values(ascending=False).head(200)\n",
    "    wells_volum_sum = top_200_wells.sum()\n",
    "\n",
    "    #calcular la ganancia potencial en el target de los 200 pozos principales\n",
    "    revenue = wells_volum_sum * 4500 - 100000000\n",
    "    \n",
    "    return revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ganancias potenciales para los 200 principales pozos en la region \"1\": 24150866.966815114\n"
     ]
    }
   ],
   "source": [
    "#calcular las potenciales ganancias en cada region\n",
    "#top_predicted_wells_0, gains_0 = well_gains(target_valid_0, predictions_0)\n",
    "revenue_1 = wells_revenue(target_to_revenue_1)\n",
    "#top_predicted_wells_2, gains_2 = well_gains(target_valid_2, predictions_2)\n",
    "\n",
    "#print('Ganancias potenciales para los 200 principales pozos en la region \"0\":', gains_0)\n",
    "print('Ganancias potenciales para los 200 principales pozos en la region \"1\":', revenue_1)\n",
    "#print('Ganancias potenciales para los 200 principales pozos en la region \"2\":', gains_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En las tres regiones las ganancias resultan negativas. Propongo la region \"0\" en vista de que el número negativo es menor que en las otras regiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calcular riesgos y ganancias para cada región"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Utilizando las predicciones que almacenaste en 4.2, emplea el bootstrapping con 1000 muestras para hallar las distribucion de los beneficios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para crear submuestras con bootstrapping\n",
    "def bootstrap(predictions):\n",
    "    \n",
    "    state = np.random.RandomState(12345)\n",
    "    values = []\n",
    "    \n",
    "    \n",
    "    for i in range(1000):\n",
    "        predicted_subsamples = predictions.sample(n=500, random_state=state, replace=True)\n",
    "           \n",
    "        values.append(predicted_subsamples)\n",
    "    \n",
    "    values = pd.Series(values)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Encuentra el beneficio promedio, el intervalo de confianza del 95% y el riesgo de pérdidas. La pérdida es una ganancia negativa, calcúlala como una probabilidad y luego exprésala como un porcentaje"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
