{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo de Regresión Lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### En el siguiente proyecto estaré desarrollando un modelo de machine learning para una compañia de petróleo que desea saber cual es el mejor lugar para abrir 200 nuevos pozos. Estaré estudiando los beneficios y riesgos potenciales basados en los datos sobre muestras de crudo en tres regiones distintas y el modelo deberá seleccionar la región con el mayor márgen de beneficio para la empresa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tabla de contenido:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Inicialización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importar librerías\n",
    "import pandas as pd\n",
    "from sklearn.metrics import recall_score, precision_score, confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib as plt \n",
    "from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cargar datasets\n",
    "dataset_0 = pd.read_csv('files /data/geo_data_0.csv')\n",
    "dataset_1 = pd.read_csv('files /data/geo_data_1.csv')\n",
    "dataset_2 = pd.read_csv('files /data/geo_data_2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1. Preparar Dataset 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>txEyH</td>\n",
       "      <td>0.705745</td>\n",
       "      <td>-0.497823</td>\n",
       "      <td>1.221170</td>\n",
       "      <td>105.280062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2acmU</td>\n",
       "      <td>1.334711</td>\n",
       "      <td>-0.340164</td>\n",
       "      <td>4.365080</td>\n",
       "      <td>73.037750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>409Wp</td>\n",
       "      <td>1.022732</td>\n",
       "      <td>0.151990</td>\n",
       "      <td>1.419926</td>\n",
       "      <td>85.265647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>iJLyR</td>\n",
       "      <td>-0.032172</td>\n",
       "      <td>0.139033</td>\n",
       "      <td>2.978566</td>\n",
       "      <td>168.620776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xdl7t</td>\n",
       "      <td>1.988431</td>\n",
       "      <td>0.155413</td>\n",
       "      <td>4.751769</td>\n",
       "      <td>154.036647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id        f0        f1        f2     product\n",
       "0  txEyH  0.705745 -0.497823  1.221170  105.280062\n",
       "1  2acmU  1.334711 -0.340164  4.365080   73.037750\n",
       "2  409Wp  1.022732  0.151990  1.419926   85.265647\n",
       "3  iJLyR -0.032172  0.139033  2.978566  168.620776\n",
       "4  Xdl7t  1.988431  0.155413  4.751769  154.036647"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualizar datos\n",
    "dataset_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#visualizar tipo de datos\n",
    "dataset_0.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "f0         0\n",
       "f1         0\n",
       "f2         0\n",
       "product    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificar datos ausentes\n",
    "dataset_0.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#verificar datos duplicados en todo el dataset\n",
    "print(dataset_0.duplicated().sum())\n",
    "\n",
    "#verificar datos duplicados en los id\n",
    "print(dataset_0['id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dataset 0 se visualizan tipos de datos correctos en cada columna y no hay datos ausentes. En cuanto a duplicados, en el dataset completo no encontré ninguno, sin embargo, al revisar la columna de IDs únicos, encontré 10 datos duplicados, los cuales voy a eliminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eliminar datos duplicados de la columna ID\n",
    "dataset_0 = dataset_0.drop_duplicates(subset='id')\n",
    "\n",
    "#verificar nuevamente datos duplicados \n",
    "dataset_0['id'].duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.2. Preparar Dataset 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kBEdx</td>\n",
       "      <td>-15.001348</td>\n",
       "      <td>-8.276000</td>\n",
       "      <td>-0.005876</td>\n",
       "      <td>3.179103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62mP7</td>\n",
       "      <td>14.272088</td>\n",
       "      <td>-3.475083</td>\n",
       "      <td>0.999183</td>\n",
       "      <td>26.953261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vyE1P</td>\n",
       "      <td>6.263187</td>\n",
       "      <td>-5.948386</td>\n",
       "      <td>5.001160</td>\n",
       "      <td>134.766305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KcrkZ</td>\n",
       "      <td>-13.081196</td>\n",
       "      <td>-11.506057</td>\n",
       "      <td>4.999415</td>\n",
       "      <td>137.945408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AHL4O</td>\n",
       "      <td>12.702195</td>\n",
       "      <td>-8.147433</td>\n",
       "      <td>5.004363</td>\n",
       "      <td>134.766305</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id         f0         f1        f2     product\n",
       "0  kBEdx -15.001348  -8.276000 -0.005876    3.179103\n",
       "1  62mP7  14.272088  -3.475083  0.999183   26.953261\n",
       "2  vyE1P   6.263187  -5.948386  5.001160  134.766305\n",
       "3  KcrkZ -13.081196 -11.506057  4.999415  137.945408\n",
       "4  AHL4O  12.702195  -8.147433  5.004363  134.766305"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualizar datos\n",
    "dataset_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#verificar informacion general del dataset\n",
    "dataset_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "f0         0\n",
       "f1         0\n",
       "f2         0\n",
       "product    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificar datos ausentes\n",
    "dataset_1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#verificar datos duplicados en todo el dataset\n",
    "print(dataset_1.duplicated().sum())\n",
    "\n",
    "#verificar datos duplicados en los IDs\n",
    "print(dataset_1['id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dataset 1 se visualizan tipos de datos correctos en cada columna y no hay datos ausentes. En cuanto a duplicados, en el dataset completo no encontré ninguno, sin embargo, al revisar la columna de IDs únicos, encontré 4 datos duplicados, los cuales voy a eliminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eliminar datos duplicados de la columna ID\n",
    "dataset_1 = dataset_1.drop_duplicates(subset='id')\n",
    "\n",
    "#verificar nuevamente datos duplicados \n",
    "dataset_1['id'].duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.3. Preparar Dataset 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>f0</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fwXo0</td>\n",
       "      <td>-1.146987</td>\n",
       "      <td>0.963328</td>\n",
       "      <td>-0.828965</td>\n",
       "      <td>27.758673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WJtFt</td>\n",
       "      <td>0.262778</td>\n",
       "      <td>0.269839</td>\n",
       "      <td>-2.530187</td>\n",
       "      <td>56.069697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ovLUW</td>\n",
       "      <td>0.194587</td>\n",
       "      <td>0.289035</td>\n",
       "      <td>-5.586433</td>\n",
       "      <td>62.871910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>q6cA6</td>\n",
       "      <td>2.236060</td>\n",
       "      <td>-0.553760</td>\n",
       "      <td>0.930038</td>\n",
       "      <td>114.572842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WPMUX</td>\n",
       "      <td>-0.515993</td>\n",
       "      <td>1.716266</td>\n",
       "      <td>5.899011</td>\n",
       "      <td>149.600746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id        f0        f1        f2     product\n",
       "0  fwXo0 -1.146987  0.963328 -0.828965   27.758673\n",
       "1  WJtFt  0.262778  0.269839 -2.530187   56.069697\n",
       "2  ovLUW  0.194587  0.289035 -5.586433   62.871910\n",
       "3  q6cA6  2.236060 -0.553760  0.930038  114.572842\n",
       "4  WPMUX -0.515993  1.716266  5.899011  149.600746"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#visualizar datos\n",
    "dataset_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count   Dtype  \n",
      "---  ------   --------------   -----  \n",
      " 0   id       100000 non-null  object \n",
      " 1   f0       100000 non-null  float64\n",
      " 2   f1       100000 non-null  float64\n",
      " 3   f2       100000 non-null  float64\n",
      " 4   product  100000 non-null  float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "#visualizar informacion general del dataset\n",
    "dataset_2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "f0         0\n",
       "f1         0\n",
       "f2         0\n",
       "product    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificar datos ausentes\n",
    "dataset_2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#verificar datos duplicados en el dataset completo\n",
    "print(dataset_2.duplicated().sum())\n",
    "\n",
    "#verificar datos duplicados en los IDs\n",
    "print(dataset_2['id'].duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dataset 2 se visualizan tipos de datos correctos en cada columna y no hay datos ausentes. En cuanto a duplicados, en el dataset completo no encontré ninguno, sin embargo, al revisar la columna de IDs únicos, encontré 4 datos duplicados, los cuales voy a eliminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eliminar datos duplicados de la columna ID\n",
    "dataset_2 = dataset_2.drop_duplicates(subset='id')\n",
    "\n",
    "#verificar nuevamente datos duplicados \n",
    "dataset_2['id'].duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya se encuentran los tres datasets preparados para comenzar a trabajar con ellos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modelo de regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definir variables para entrenar el modelo en el dataset 0\n",
    "features_0 = dataset_0.drop(['id', 'product'], axis=1)\n",
    "target_0 = dataset_0['product']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Segmentar el dataset 0 en conjuntos de entrenamiento y validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#segmentar el dataset 0 en conjuntos de entrenamiento y valiacion 75:25\n",
    "\n",
    "features_train_0, features_valid_0, target_train_0, target_valid_0 = train_test_split(features_0, target_0, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Entrenar el modelo y hacer predicciones para el conjunto de validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entrenar el modelo \n",
    "model = LinearRegression()\n",
    "model.fit(features_train_0, target_train_0)\n",
    "predictions_valid_0 = model.predict(features_valid_0)\n",
    "\n",
    "predictions_0 = pd.Series(predictions_valid_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Volumen medio de reservas predicho y RMSE del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volúmen medio verdadero de reservas región \"0\": 92.15820490940044\n",
      "Volúmen medio de reservas predicho por el modelo: 92.78915638280621\n",
      "RMSE del modelo: 1.4381713586741687\n",
      "\n",
      "Volúmen máximo de reserva: 185.33836970504785\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#calcular RMSE del modelo\n",
    "mse_model = mean_squared_error(target_valid_0, predictions_0)\n",
    "rmse_model = mse_model ** 0.05\n",
    "\n",
    "print('Volúmen medio verdadero de reservas región \"0\":', target_valid_0.mean())\n",
    "print('Volúmen medio de reservas predicho por el modelo:', predictions_0.mean())\n",
    "print('RMSE del modelo:', rmse_model)\n",
    "print()\n",
    "print('Volúmen máximo de reserva:', target_valid_0.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Análisis de resultados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de calcular el RMSE para las prediciones del modelo y obtener un valor de 1.43, me doy cuenta de que el modelo es bastante acertado considerando que estamos manejando un volumen máximo de reservas de hasta 185.33 miles de barriles. De modo que el modelo me parece lo bastante adecuado para la ejecución de la tarea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Función para modelo de regresión lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para modelo de regresion lineal\n",
    "def linear_regresion_model(features, target):\n",
    "    #segmentar conjuntos de entrenamiento y validacion\n",
    "    features_train, features_valid, target_train, target_valid = train_test_split(features, target, test_size=0.25, random_state=12345)\n",
    "    \n",
    "    #entrenar un modelo de regresion lineal \n",
    "    model = LinearRegression()\n",
    "    model.fit(features_train, target_train)\n",
    "    \n",
    "    #realizar predicciones con el conjunto de validacion\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    predictions = pd.Series(predictions_valid)\n",
    "    \n",
    "    #calcular el promedio  de las predicciones del modelo\n",
    "    predictions_mean = predictions_valid.mean()\n",
    "    \n",
    "    #calcular promedio de volumen verdadero de reservas\n",
    "    target_valid_mean = target_valid.mean()\n",
    "    \n",
    "    #calcular RMSE del modelo\n",
    "    mse_model = mean_squared_error(target_valid, predictions_valid)\n",
    "    rmse_model = mse_model ** 0.05\n",
    "    \n",
    "    return predictions, predictions_mean, target_valid_mean, rmse_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volúmen medio verdadero de reservas región \"1\": 69.18604400957675\n",
      "Volúmen medio de reservas predicho por el modelo: 69.17831957030432\n",
      "RMSE del modelo: 0.988642715640864\n"
     ]
    }
   ],
   "source": [
    "#entrenando el modelo en dataset 1\n",
    "features_1 = dataset_1.drop(['id', 'product'], axis=1)\n",
    "target_1 = dataset_1['product']\n",
    "\n",
    "predictions_1, predictions_mean_1, target_valid_mean_1, rmse_model_1 = linear_regresion_model(features_1, target_1)\n",
    "\n",
    "print('Volúmen medio verdadero de reservas región \"1\":', target_valid_mean_1)\n",
    "print('Volúmen medio de reservas predicho por el modelo:', predictions_mean_1)\n",
    "print('RMSE del modelo:', rmse_model_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el dataset 1 el modelo también es bantante preciso, con un RMSE de 0.98 en las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volúmen medio verdadero de reservas región \"2\": 94.7851093536914\n",
      "Volúmen medio de reservas predicho por el modelo: 94.86572480562035\n",
      "RMSE del modelo: 1.4463995400767802\n"
     ]
    }
   ],
   "source": [
    "#entrenando el modelo en dataset 2\n",
    "features_2 = dataset_2.drop(['id', 'product'], axis=1)\n",
    "target_2 = dataset_2['product']\n",
    "\n",
    "predictions_2, predictions_mean_2, target_valid_mean_2, rmse_model_2 = linear_regresion_model(features_2, target_2)\n",
    "\n",
    "print('Volúmen medio verdadero de reservas región \"2\":', target_valid_mean_2)\n",
    "print('Volúmen medio de reservas predicho por el modelo:', predictions_mean_2)\n",
    "print('RMSE del modelo:', rmse_model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, en el dataset 2, el modelo da un RMSE de 1.44 en las predicciones. \n",
    "En los tres casos, el modelo erró entre 0.98 y 1.44. Sin embargo, me parece que el modelo es aceptable en los tres datasets ya que la diferencia no es un número demasiado alto, sobretodo cuando lo comparamos con los volúmenes de reserva máximos con los que estamos trabajando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cálculo de ganancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alamcacenar los valores para el cálculo en variables\n",
    "\n",
    "inversion = 100000000\n",
    "wells = 200\n",
    "media_per_well = inversion / wells\n",
    "min_units_per_well = media_per_well / 4500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unidades de reserva mínimas para evitar pérdidas en la inversión: 111.11111111111111\n",
      "Media de unidades de reserva en la región \"0\": 92.49968421774354\n",
      "Media de unidades de reserva en la región \"1\": 68.82391591804064\n",
      "Media de unidades de reserva en la región \"2\": 94.99834211933378\n"
     ]
    }
   ],
   "source": [
    "#calcular la cantidad media de reservas en cada region\n",
    "print('Unidades de reserva mínimas para evitar pérdidas en la inversión:', min_units_per_well)\n",
    "print('Media de unidades de reserva en la región \"0\":', dataset_0['product'].mean())\n",
    "print('Media de unidades de reserva en la región \"1\":', dataset_1['product'].mean())\n",
    "print('Media de unidades de reserva en la región \"2\":', dataset_2['product'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En promedio, ninguna de las zonas llega al promedio mínimo de reservas que se necesitan para no tener pérdidas con la inversión de 1 millón de dólares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Función para el cálculo de las ganancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        103.950372\n",
       "1         73.687869\n",
       "2        101.015288\n",
       "3         94.048415\n",
       "4         87.559552\n",
       "            ...    \n",
       "24993     63.963223\n",
       "24994    139.862730\n",
       "24995     78.444653\n",
       "24996     71.082768\n",
       "24997     66.054854\n",
       "Length: 24998, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#funcion para calcular las ganancias potenciales de los 200 principales pozos por region\n",
    "def well_gains(target, predictions):\n",
    "    \n",
    "    #elegir los 200 pozos con predicciones más altas y sumar el volumen objetivo en cada region\n",
    "    top_200_predicted = predictions.sort_values(ascending=False).head(200)\n",
    "    \n",
    "    top_200_target = target[top_200_predicted.index][:count]\n",
    "    \n",
    "    target_wells_volum_sum = top_200_target.sum()\n",
    "\n",
    "    #calcular la ganancia potencial de los 200 pozos principales por region\n",
    "    gains_wells_cal = target_wells_volum_sum * 4500 - 100000000\n",
    "    \n",
    "    return top_200_predicted, top_200_target, gains_wells_cal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ganancias potenciales para los 200 principales pozos en la region \"0\": 3218.5086480958175\n",
      "Ganancias potenciales para los 200 principales pozos en la region \"1\": 3604.0189755926785\n",
      "Ganancias potenciales para los 200 principales pozos en la region \"2\": 3367.5287398377804\n"
     ]
    }
   ],
   "source": [
    "#calcular las potenciales ganancias en cada region\n",
    "top_predicted_wells_0, top_predicted_wells_1, top_predicted_wells_2, potential_gain_0, potential_gain_1, potential_gain_2 = well_gain_cal(predictions_0, predictions_1, predictions_2)\n",
    "\n",
    "print('Ganancias potenciales para los 200 principales pozos en la region \"0\":', potential_gain_0)\n",
    "print('Ganancias potenciales para los 200 principales pozos en la region \"1\":', potential_gain_1)\n",
    "print('Ganancias potenciales para los 200 principales pozos en la region \"2\":', potential_gain_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bajo este enfoque, las ganancias más altas las hallamos en la región número 1 según el modelo de predicción. Estas ganancias son de aproximadamente 3,6 millones. De manera que yo propondría esta región para el desarrollo de pozos petrolíferos, por ser la más alta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calcular riesgos y ganancias para cada región"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Utilizando las predicciones que almacenaste en 4.2, emplea el bootstrapping con 1000 muestras para hallar las distribucion de los beneficios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables que almacenan los 200 principales pozos por región\n",
    "#top_predicted_wells_0, top_predicted_wells_1, top_predicted_wells_2\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
